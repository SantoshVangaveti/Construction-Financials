{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e86dacb",
   "metadata": {},
   "source": [
    "Please read the Read me PDF for overall undestaing of project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8420c99c",
   "metadata": {},
   "source": [
    "## Labor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df023a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter finger check API keys, link of API documentation https://developer.fingercheck.com/api/help \n",
    "\n",
    "%env FINGERCHECK_APIKEY= #Input API key \n",
    "%env FINGERCHECK_CLIENT_SECRET= #Input API key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046b1211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to the fingercheck end point and pulling the data for the dates needed\n",
    "# This end point contains most of the data needed for my analysis except the wages\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time \n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "# Retrieve API keys from environment variables for security\n",
    "APIKEY = os.getenv('FINGERCHECK_APIKEY')\n",
    "CLIENT_SECRET_KEY = os.getenv('FINGERCHECK_CLIENT_SECRET')\n",
    "\n",
    "# Function to make the API request and return a DataFrame\n",
    "def get_all_time_cards_for_date_range(start_date, end_date):\n",
    "    base_url = \"https://developer.fingercheck.com/api\"\n",
    "    endpoint = \"/v1/Reports/GetAllTimeCardsForDateRange\"\n",
    "    params = {\n",
    "        \"startDate\": start_date,\n",
    "        \"endDate\": end_date\n",
    "    }\n",
    "    headers = {\n",
    "        \"APIKEY\": APIKEY,\n",
    "        \"ClientSecretKey\": CLIENT_SECRET_KEY\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(base_url + endpoint, params=params, headers=headers, timeout=60)\n",
    "        response.raise_for_status()  # Raises an HTTPError if the HTTP request returned an unsuccessful status code\n",
    "        data = response.json()\n",
    "        df = pd.DataFrame(data)\n",
    "        return df\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        print(f\"HTTP error occurred: {http_err}\")\n",
    "    except requests.exceptions.ConnectionError as conn_err:\n",
    "        print(f\"Error Connecting: {conn_err}\")\n",
    "    except requests.exceptions.Timeout as timeout_err:\n",
    "        print(f\"Timeout error: {timeout_err}\")\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        print(f\"An error occurred: {err}\")\n",
    "    return None\n",
    "\n",
    "# Function to retry the API request in case of failure\n",
    "def get_all_time_cards_for_date_range_with_retry(start_date, end_date, retries=3, delay=5):\n",
    "    for attempt in range(retries):\n",
    "        result = get_all_time_cards_for_date_range(start_date, end_date)\n",
    "        if isinstance(result, pd.DataFrame):\n",
    "            return result\n",
    "        else:\n",
    "            print(f\"Attempt {attempt + 1} failed. Retrying in {delay} seconds...\")\n",
    "            time.sleep(delay)\n",
    "    return None\n",
    "\n",
    "# Set the start date and end date, with the end date being yesterday\n",
    "start_date = \"2023-12-10\"\n",
    "end_date = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')  # Yesterday's date in 'YYYY-MM-DD' format\n",
    "\n",
    "# Make the API call with retries\n",
    "data_df_LATEST = get_all_time_cards_for_date_range_with_retry(start_date, end_date)\n",
    "\n",
    "# Check the result and print or handle accordingly\n",
    "if isinstance(data_df_LATEST, pd.DataFrame):\n",
    "    print(data_df_LATEST.head())\n",
    "else:\n",
    "    print(\"Failed to retrieve data after multiple attempts.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678e2d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the API for wide range of dates will result in errors, and its unnecssary to extract the same data again and again\n",
    "# so I extrated data from year 2020 to 2023 and saved it to the excel file\n",
    "# which I will merge with the recent data pulled at my intended regular intervels\n",
    "\n",
    "csv_file_path = #give path for the file\n",
    "\n",
    "Old_data = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75fdab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fingercheck_raw_data = pd.concat([Old_data, data_df_LATEST], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d4acb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requesting rates/hourly wage information from API, give the dates for data needed. \n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "# Calculate yesterday's date\n",
    "end_date = (datetime.now() - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "def get_all_time_cards_for_date_range(start_date, end_date):\n",
    "    base_url = \"https://developer.fingercheck.com/api\"\n",
    "    endpoint = \"/v1/Reports/GetEmployeeActiveRates\"\n",
    "    params = {\n",
    "        \"startDate\": start_date,\n",
    "        \"endDate\": end_date\n",
    "    }\n",
    "    headers = {\n",
    "        \"APIKEY\": APIKEY,\n",
    "        \"ClientSecretKey\": CLIENT_SECRET_KEY\n",
    "    }\n",
    "\n",
    "    response = requests.get(base_url + endpoint, params=params, headers=headers)\n",
    "   \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        df = pd.DataFrame(data)\n",
    "        return df\n",
    "    else:\n",
    "        return f\"Error: {response.status_code}, {response.text}\"\n",
    "\n",
    "# Example usage:\n",
    "rates_df = get_all_time_cards_for_date_range(\"2020-01-01\", end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fd3749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stripping all the data to lower case. \n",
    "\n",
    "fingercheck_data = fingercheck_raw_data.copy()\n",
    "fingercheck_data = fingercheck_data.applymap(lambda x: x.lower() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aec6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\n",
    "            \"EmployeeID\", \"EmployeeNumber\", \n",
    "            \"Position\", \"FirstName\", \"MiddleInitial\", \n",
    "            \"LastName\", \"DateWorked\", \"Hours\",\"JobDescriptionPunch\",'CostCenter1', 'CostCenter2',\n",
    "            'DivisionEmployeeStatus'\n",
    "        ]\n",
    "\n",
    "fingercheck_data = fingercheck_data[columns_to_keep]\n",
    "\n",
    "fingercheck_hours = fingercheck_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b96c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging data pulled from two end points\n",
    "\n",
    "merged_df = fingercheck_hours.merge(rates_df, on='EmployeeID', how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b858b71",
   "metadata": {},
   "source": [
    "We recently started making more use of fingercheck, so we do not have wages and labor classification for the \n",
    "employees who are no longer working with us. And some of the projects are started years ago. \n",
    "So we took an avarage wage rate and filled in all the nan values. \n",
    "\n",
    "But for all the recent projects wage rates are accurate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574bfae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['Rate'] = merged_df['Rate'].fillna(30)\n",
    "merged_df['Position'] = merged_df['Position'].fillna('l')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1d1d20",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1304e157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'DateWorked' column to a datetime object\n",
    "merged_df['DateWorked'] = pd.to_datetime(merged_df['DateWorked'])\n",
    "\n",
    "# Create a function to calculate hours paid based on 'Position' and day of the week\n",
    "def calculate_hours_paid(row):\n",
    "    if row['Position'] == 'l':\n",
    "        if row['DateWorked'].day_name() == 'Saturday':\n",
    "            return 8  # 'l' gets paid for 8 hours on Saturday\n",
    "        else:\n",
    "            return 9  # 'l' gets paid for 9 hours from Monday to Friday\n",
    "    else:\n",
    "        return 8  # Default 8 hours for other positions\n",
    "\n",
    "# Add a new 'HoursPaidFor' column based on the 'Position' and 'DateWorked' columns\n",
    "merged_df['HoursPaidFor'] = merged_df.apply(calculate_hours_paid, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3b7d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'DateWorked' column to datetime\n",
    "merged_df['DateWorked'] = pd.to_datetime(merged_df['DateWorked'])\n",
    "\n",
    "# Identify rows that are Saturdays\n",
    "merged_df['IsSaturday'] = merged_df['DateWorked'].dt.dayofweek == 5\n",
    "\n",
    "# Update the rate for Saturdays\n",
    "merged_df.loc[merged_df['IsSaturday'], 'Rate'] *= 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd5de3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating labor cost\n",
    "merged_df['LaborCost'] = merged_df['HoursPaidFor'] * merged_df['Rate']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eac05a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Group by 'JobDescriptionPunch' to perform calculations for each project\n",
    "grouped = merged_df.groupby('JobDescriptionPunch')\n",
    "\n",
    "# Calculate M&F_Hours (sum of hours for masons and foremen)\n",
    "mf_hours = grouped.apply(lambda x: x[x['Position'].isin(['m', 'f'])]['HoursPaidFor'].sum())\n",
    "\n",
    "# Calculate Avg_M&F Rate (average rate for masons and foremen) and round to one decimal\n",
    "avg_mf_rate = grouped.apply(lambda x: round(x[x['Position'].isin(['m', 'f'])]['Rate'].mean(), 1))\n",
    "\n",
    "# Calculate L_Hours (sum of hours for labor)\n",
    "l_hours = grouped.apply(lambda x: x[x['Position'] == 'l']['HoursPaidFor'].sum())\n",
    "\n",
    "# Calculate Avg_L Rate (average rate for labor) and round to one decimal\n",
    "avg_l_rate = grouped.apply(lambda x: round(x[x['Position'] == 'l']['Rate'].mean(), 1))\n",
    "\n",
    "# Calculate M vs L Ratio and format to two decimals\n",
    "m_vs_l_ratio = l_hours / mf_hours.replace({0: np.nan})  # Replace 0 with NaN to avoid division by zero\n",
    "m_vs_l_ratio = m_vs_l_ratio.apply(lambda x: f'1:{x:.2f}' if pd.notna(x) else '1:âˆž')\n",
    "\n",
    "# Calculate Total hours (sum of hours paid for each project)\n",
    "total_hours = grouped['HoursPaidFor'].sum()\n",
    "\n",
    "# Calculate Ave_Rate (average rate for each project) and round to one decimal\n",
    "ave_rate = grouped['Rate'].mean().round(1)\n",
    "\n",
    "# Calculate Total Labor Cost (sum of LaborCost for each project)\n",
    "total_cost = grouped['LaborCost'].sum()\n",
    "\n",
    "# Find the LastDateWorked for each project\n",
    "last_date_worked = grouped['DateWorked'].max()\n",
    "\n",
    "# Create the labor_analysis DataFrame\n",
    "labor_analysis = pd.DataFrame({\n",
    "    'Project Name': mf_hours.index,\n",
    "    'M&F_Hours': mf_hours.values,\n",
    "    'Avg_M&F Rate': avg_mf_rate.values,\n",
    "    'L_Hours': l_hours.values,\n",
    "    'Avg_L Rate': avg_l_rate.values,\n",
    "    'M vs L Ratio': m_vs_l_ratio.values,\n",
    "    'Total Hours': total_hours.values,\n",
    "    'Ave_Rate': ave_rate.values,\n",
    "    'Total Labor Cost': total_cost.values,\n",
    "    'LastDateWorked': last_date_worked.values\n",
    "})\n",
    "\n",
    "# Reset index to make sure 'Project' is a column and not an index\n",
    "labor_analysis.reset_index(drop=True, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071a7ab6",
   "metadata": {},
   "source": [
    "# Material Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a985f658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load downloaded CSV file from quickbooks\n",
    "\n",
    "import pandas as pd\n",
    "file_path = # file path\n",
    "\n",
    "# Load the file into a DataFrame\n",
    "inv = pd.read_csv(file_path)\n",
    "\n",
    "inv = inv.applymap(lambda x: x.lower() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7081d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to keep\n",
    "columns_to_keep = ['Trans #', 'Type', 'Date', 'Num', 'Name', 'Source Name', 'Account', \n",
    "                   'Billing Status', 'Split', 'Paid', 'Amount', 'Account Type']\n",
    "\n",
    "# Select only the desired columns\n",
    "Material_cost = inv[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d388fe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify rows with all NaN values\n",
    "rows_with_all_nan = Material_cost.isna().all(axis=1)\n",
    "\n",
    "# Check how many such rows exist\n",
    "num_rows_with_all_nan = rows_with_all_nan.sum()\n",
    "print(f\"There are {num_rows_with_all_nan} rows with all NaN values.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93b7d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "Material_cost = Material_cost.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9846d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'Name' and aggregate the sum of 'Amount' and the max of 'Date'\n",
    "grouped = Material_cost.groupby('Name').agg(MaterialCost=('Amount', 'sum'), Latest_Date=('Date', 'max'))\n",
    "\n",
    "# Reset the index\n",
    "Material_cost_byproject = grouped.reset_index()\n",
    "\n",
    "# Rename the 'Name' column to 'Project Name'\n",
    "Material_cost_byproject = Material_cost_byproject.rename(columns={'Name': 'Project Name'})\n",
    "\n",
    "# Sort by 'Latest_Date' in descending order\n",
    "Material_cost_byproject = Material_cost_byproject.sort_values(by='Latest_Date', ascending=False)\n",
    "\n",
    "# Drop the 'Latest_Date' column if you don't need it in the final dataframe\n",
    "Material_cost_byproject = Material_cost_byproject.drop(columns=['Latest_Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c60e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merding labor and material data frames on project name as unique ID\n",
    "\n",
    "Labor_Material = labor_analysis.merge(Material_cost_byproject, on='Project Name', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7ff4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Labor_Material.sort_values(by='LastDateWorked', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a343f0",
   "metadata": {},
   "source": [
    "# Project Budget / Project Contract amount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e138d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the Textura data \n",
    "\n",
    "file_path = # file path\n",
    "# Load the CSV file into a DataFrame\n",
    "Tex = pd.read_csv(file_path,header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e39437",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Tex['Subcontract Number'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde354cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Tex['Project Name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67457063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find unique pairs of 'Subcontract Number' and 'Project Name'\n",
    "unique_pairs = Tex[['Subcontract Number', 'Project Name']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf3cf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Calculate the change orders and revised budget\n",
    "Tex['Change Orders'] = Tex['Previously Approved Change Orders'] + Tex['Current Change Orders']\n",
    "Tex['Revised Budget'] = Tex['Original Budget'] + Tex['Change Orders']\n",
    "\n",
    "# Group by 'Project Name', 'Subcontract Number', and 'Draw Number', then aggregate the required columns\n",
    "grouped = Tex.groupby(['Project Name', 'Subcontract Number', 'Draw Number']).agg({\n",
    "    'Draw Date': 'first',\n",
    "    'Subcontract Date': 'first',\n",
    "    'Original Budget': 'sum',\n",
    "    'Change Orders': 'sum',\n",
    "    'Revised Budget': 'sum',\n",
    "    'Total Work Completed and Material Stored to Date': 'sum',\n",
    "}).reset_index()\n",
    "\n",
    "# Get the index of the row with the maximum draw number for each subcontract within each project\n",
    "latest_draw_indices = grouped.groupby(['Project Name', 'Subcontract Number'])['Draw Number'].idxmax()\n",
    "\n",
    "# Filter the dataframe to only include rows with the latest draw number for each subcontract in each project\n",
    "Textura_req = grouped.loc[latest_draw_indices]\n",
    "\n",
    "# Convert the 'Draw Date' column to datetime format\n",
    "Textura_req['Draw Date'] = pd.to_datetime(Textura_req['Draw Date'])\n",
    "\n",
    "# Sort the dataframe by 'Project Name', 'Subcontract Number', and 'Draw Date'\n",
    "Textura_req = Textura_req.sort_values(by=['Project Name', 'Subcontract Number', 'Draw Date'], ascending=[True, True, False])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ff8937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fe2fb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b234099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uploading manual requisition file\n",
    "\n",
    "file_path = # file path\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "Manual = pd.read_excel(file_path,header=1)\n",
    "\n",
    "Manual = Manual.drop([ 'Unnamed: 8', 'Unnamed: 9'], axis=1)\n",
    "Manual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5201506",
   "metadata": {},
   "source": [
    "Adding data set from manual req and textura "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ed38e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Textura = pd.concat([Textura_req, Manual], ignore_index=True)\n",
    "Textura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ff87a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Textura = Textura.applymap(lambda x: x.lower() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da14122a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging material, labor and budget on project name\n",
    "\n",
    "Labor_Material_Textura = Labor_Material.merge(Textura, on='Project Name', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65180001",
   "metadata": {},
   "outputs": [],
   "source": [
    "Labor_Material_Textura.sort_values(by='Draw Date', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4694ee85",
   "metadata": {},
   "outputs": [],
   "source": [
    "Project_report = Labor_Material_Textura.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01269139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of specified projects\n",
    "specified_projects = [# filtering only the projects needed]\n",
    "\n",
    "# Normalize case for comparison (optional, remove if exact match is needed)\n",
    "specified_projects = [project.lower() for project in specified_projects]\n",
    "Project_report['Project Name'] = Project_report['Project Name'].str.lower()\n",
    "\n",
    "# Filter the DataFrame\n",
    "Filtered_Project_report= Project_report[Project_report['Project Name'].isin(specified_projects)]\n",
    "\n",
    "# Display the new DataFrame\n",
    "Filtered_Project_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc842bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List of projects which have CCIP/OCIP insurence\n",
    "ccip_ocip_projects = [#]\n",
    "\n",
    "# Function to determine the insurance type\n",
    "def determine_insurance_type(project_name):\n",
    "    project_name = project_name.strip().lower()  # Normalize the string\n",
    "    if project_name in ccip_ocip_projects:\n",
    "        return 'CCIP/OCIP'\n",
    "    else:\n",
    "        return 'Traditional'\n",
    "\n",
    "# Apply the function to create a new column\n",
    "Filtered_Project_report['InsuranceType'] = Filtered_Project_report['Project Name'].apply(determine_insurance_type)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "Filtered_Project_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6208b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Project_final = Filtered_Project_report.copy()\n",
    "Project_final = Filtered_Project_report.copy()\n",
    "\n",
    "\n",
    "# Calculate the percentage of project completed\n",
    "Project_final[\"% completed to date\"] = (Project_final['Total Work Completed and Material Stored to Date'] / Project_final['Revised Budget']) #* 100\n",
    "\n",
    "# Calculating work mem comp\n",
    "Project_final['Workmen comp 18% of labor'] = Project_final.apply(\n",
    "    lambda row: 0.18 * row['Total Labor Cost']\n",
    "                if row['InsuranceType'] == 'Traditional' else 0, \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Calculating insurence\n",
    "Project_final['Insurance-10% of work completed'] = Project_final.apply(\n",
    "    lambda row: 0.10 * row['Total Work Completed and Material Stored to Date'] \n",
    "                if row['InsuranceType'] == 'Traditional' else 0, \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Calculating overhead\n",
    "Project_final['Overhead-10% of work completed'] = 0.10 * Project_final['Total Work Completed and Material Stored to Date']\n",
    "\n",
    "# Calculate and update 'Profit' column\n",
    "Project_final['Profit'] = (Project_final['Total Work Completed and Material Stored to Date'] \n",
    "                           - Project_final['Total Labor Cost']\n",
    "                           - Project_final['MaterialCost']\n",
    "                           - Project_final['Workmen comp 18% of labor']\n",
    "                           - Project_final['Overhead-10% of work completed'] \n",
    "                           - Project_final['Insurance-10% of work completed'])\n",
    "\n",
    "# Calculate and update 'Profit %' column\n",
    "Project_final['Profit %'] = (Project_final['Profit'] / Project_final['Total Work Completed and Material Stored to Date']) #* 100\n",
    "# Convert to string and append '%'\n",
    "#Project_final['Profit %'] = Project_final['Profit %'].apply(lambda x: f'{x:.2f}%' if pd.notna(x) else x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae3c51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Project_final['Total Labor Cost for work completed %'] = (Project_final['Total Labor Cost'] / Project_final[\"Total Work Completed and Material Stored to Date\"]) #* 100\n",
    "# Convert to string and append '%'\n",
    "#Project_final['Total Labor Cost for work completed %'] = Project_final['Total Labor Cost for work completed %'].apply(lambda x: f'{x:.2f}%' if pd.notna(x) else x)\n",
    "\n",
    "\n",
    "Project_final['Total Material Cost for work completed %'] = (Project_final['MaterialCost'] / Project_final[\"Total Work Completed and Material Stored to Date\"]) #* 100\n",
    "# Convert to string and append '%'\n",
    "#Project_final['Total Material Cost for work completed %'] = Project_final['Total Material Cost for work completed %'].apply(lambda x: f'{x:.2f}%' if pd.notna(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd39106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading manual change order log \n",
    "csv_file_path = # file path\n",
    "\n",
    "CO_log = pd.read_csv(csv_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f9e0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to keep\n",
    "columns_to_keep1 = ['Project Name','Work completed-Unpaid CO Total', \"Unpaid CO's amount last updated\"]\n",
    "\n",
    "# Select only the desired columns\n",
    "CO_log = CO_log[columns_to_keep1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93da5db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Project_final = Project_final.merge(CO_log, on='Project Name', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea53c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example: Remove common non-numeric characters (like $ and ,)\n",
    "Project_final[\"Work completed-Unpaid CO Total\"] = Project_final[\"Work completed-Unpaid CO Total\"].replace('[\\$,]', '', regex=True)\n",
    "\n",
    "# Then convert to numeric\n",
    "Project_final[\"Work completed-Unpaid CO Total\"] = pd.to_numeric(Project_final[\"Work completed-Unpaid CO Total\"], errors='coerce')\n",
    "\n",
    "# Perform the addition\n",
    "Project_final['Potential Profit including CO'] = Project_final['Profit'] + Project_final[\"Work completed-Unpaid CO Total\"]\n",
    "\n",
    "# Calculate 'Potential Profit including CO %'\n",
    "Project_final['Potential Profit including CO %'] = (Project_final['Potential Profit including CO'] / (Project_final[\"Work completed-Unpaid CO Total\"] + Project_final['Total Work Completed and Material Stored to Date'])) #* 100\n",
    "# Convert to string and append '%'\n",
    "#Project_final['Potential Profit including CO %'] = Project_final['Potential Profit including CO %'].apply(lambda x: f'{x:.2f}%' if pd.notna(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b214a73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Project_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8392fc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Specify the path where you want to save the Excel file\n",
    "file_path = # file path\n",
    "\n",
    "# Save the dataframe to an Excel file\n",
    "Project_final.to_excel(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2607cb8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
